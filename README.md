# ğŸ™ï¸ Emotion Recognition from Speech using Deep Learning

## ğŸ“˜ Overview
This project presents a **Speech Emotion Recognition (SER)** system capable of identifying human emotions such as **Angry**, **Disgust**, **Happy**, **Neutral**, **Sad**, and **Scared** from voice signals.  
The proposed model uses a **hybrid CNNâ€“LSTM deep learning architecture** to capture both spectral and temporal dependencies in speech features.  
It is developed as part of the **NLP Course Project at VIT Vellore** and demonstrates how AI systems can perceive emotional states through acoustic cues.

---

## ğŸ§© Motivation
Emotion plays a crucial role in human communication. Enabling machines to detect and respond to emotions can enhance **humanâ€“computer interaction**, **mental health assessment**, and **empathetic virtual assistants**.  
Despite progress in deep learning, challenges such as **cross-speaker variability**, **dataset imbalance**, and **overfitting to acted speech** persist.  
This project addresses these limitations through:
- **Multi-corpus training** using diverse datasets  
- **Feature normalization** for consistent scaling  
- **Hybrid modeling** to jointly learn local spectral and long-term temporal emotion cues  

---
